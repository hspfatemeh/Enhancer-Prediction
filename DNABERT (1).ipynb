{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rnE7pODcTBP",
        "outputId": "961bb265-fb11-429b-8503-a1ceab9c1711",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuATB5OYgxWA",
        "outputId": "ddea58ee-6ffb-4fd6-f92e-9dae71953cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1czQFh8aCPLkiY4h4fed_O6OsFQnkOh2v\n",
            "To: /content/BenchmarkEnhancerNonEnhancer.csv\n",
            "\r  0% 0.00/605k [00:00<?, ?B/s]\r100% 605k/605k [00:00<00:00, 125MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1czQFh8aCPLkiY4h4fed_O6OsFQnkOh2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xIbQS7sSbPn",
        "outputId": "717262a2-657a-4451-92da-215b4c1fb18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=191e8YNKPaZ-cVmvU8U1nL0xIFmEYvhwn\n",
            "To: /content/IndependEnhancer&NonEnhancer.csv\n",
            "\r  0% 0.00/81.6k [00:00<?, ?B/s]\r100% 81.6k/81.6k [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 191e8YNKPaZ-cVmvU8U1nL0xIFmEYvhwn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvPWzVu-vgJ0",
        "outputId": "e48a5450-c062-4e56-d186-010d5cfca307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DNABERT_2'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 123 (delta 22), reused 15 (delta 15), pack-reused 92 (from 2)\u001b[K\n",
            "Receiving objects: 100% (123/123), 882.58 KiB | 19.61 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the DNABERT_2 repository\n",
        "!git clone https://github.com/MAGICS-LAB/DNABERT_2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcRhYUBXRWkM",
        "outputId": "86888f0a-87b7-4939-f30f-ab3264264d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'triton'...\n",
            "remote: Enumerating objects: 163641, done.\u001b[K\n",
            "remote: Counting objects: 100% (827/827), done.\u001b[K\n",
            "remote: Compressing objects: 100% (560/560), done.\u001b[K\n",
            "remote: Total 163641 (delta 579), reused 305 (delta 267), pack-reused 162814 (from 3)\u001b[K\n",
            "Receiving objects: 100% (163641/163641), 398.72 MiB | 26.56 MiB/s, done.\n",
            "Resolving deltas: 100% (113600/113600), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/triton.git;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvHxxEHxWAEB",
        "outputId": "979af211-dff2-4285-84a8-c109fca3f8a0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/triton/python\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (3.31.2)\n",
            "Obtaining file:///content/triton/python\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.2.0+gitad696db6) (75.1.0)\n",
            "Building wheels for collected packages: triton\n"
          ]
        }
      ],
      "source": [
        "%cd /content/triton/python\n",
        "!pip install cmake; # build-time dependency\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIf0hITpPhV1",
        "outputId": "34fca721-baf7-43b3-f29c-fc3c442d2de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: triton 3.2.0+git33f88a99\n",
            "Uninstalling triton-3.2.0+git33f88a99:\n",
            "  Would remove:\n",
            "    /usr/local/bin/proton\n",
            "    /usr/local/bin/proton-viewer\n",
            "    /usr/local/lib/python3.11/dist-packages/__editable__.triton-3.2.0+git33f88a99.pth\n",
            "    /usr/local/lib/python3.11/dist-packages/__editable___triton_3_2_0_git33f88a99_finder.py\n",
            "    /usr/local/lib/python3.11/dist-packages/triton-3.2.0+git33f88a99.dist-info/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled triton-3.2.0+git33f88a99\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsYR1lfZl2H9",
        "outputId": "1120d4de-c389-4956-9685-75cec72c2281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmPi11D2OXb1",
        "outputId": "6c2289e7-0ebd-4268-f8fd-4d2641bc021d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops==0.6.1 (from -r /content/DNABERT_2/requirements.txt (line 1))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers==4.29.2 (from -r /content/DNABERT_2/requirements.txt (line 2))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.3.0 (from -r /content/DNABERT_2/requirements.txt (line 3))\n",
            "  Downloading peft-0.3.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting omegaconf==2.3.0 (from -r /content/DNABERT_2/requirements.txt (line 4))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting torch==1.13.1 (from -r /content/DNABERT_2/requirements.txt (line 5))\n",
            "  Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting evaluate==0.4.0 (from -r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting accelerate==0.20.3 (from -r /content/DNABERT_2/requirements.txt (line 7))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting scikit-learn==1.2.2 (from -r /content/DNABERT_2/requirements.txt (line 8))\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.3.0->-r /content/DNABERT_2/requirements.txt (line 3)) (5.9.5)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r /content/DNABERT_2/requirements.txt (line 4))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5)) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2.2.2)\n",
            "Collecting xxhash (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2024.10.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->-r /content/DNABERT_2/requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->-r /content/DNABERT_2/requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->-r /content/DNABERT_2/requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r /content/DNABERT_2/requirements.txt (line 5)) (0.45.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (17.0.0)\n",
            "Collecting dill (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2->-r /content/DNABERT_2/requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.0->-r /content/DNABERT_2/requirements.txt (line 6)) (1.17.0)\n",
            "Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=4aa657bc9478855c844a42c15df57b726e794fecbbaff7cb124276e3a887fe62\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: tokenizers, antlr4-python3-runtime, xxhash, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, fsspec, einops, dill, scikit-learn, responses, nvidia-cudnn-cu11, multiprocess, transformers, torch, datasets, accelerate, peft, evaluate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.29.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.20.3 antlr4-python3-runtime-4.9.3 datasets-3.2.0 dill-0.3.8 einops-0.6.1 evaluate-0.4.0 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 peft-0.3.0 responses-0.18.0 scikit-learn-1.2.2 tokenizers-0.13.3 torch-1.13.1 transformers-4.29.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!python3 -m pip install -r /content/DNABERT_2/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC7OGy8OtXVG",
        "outputId": "7854939a-1189-4017-cfe8-7a29cb291407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: wandb 0.19.2\n",
            "Uninstalling wandb-0.19.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/wandb\n",
            "    /usr/local/bin/wb\n",
            "    /usr/local/lib/python3.11/dist-packages/package_readme.md\n",
            "    /usr/local/lib/python3.11/dist-packages/wandb-0.19.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/wandb/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled wandb-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTSPeLOmeOIU",
        "outputId": "b2b923b8-1622-49c4-c6de-66f208af1045",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-01-20 17:52:47.170207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-20 17:52:47.196620: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-20 17:52:47.203632: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-20 17:52:48.613395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 158/158 [00:00<00:00, 857kB/s]\n",
            "tokenizer.json: 100% 168k/168k [00:00<00:00, 2.28MB/s]\n",
            "WARNING:root:Perform single sequence classification...\n",
            "WARNING:root:Perform single sequence classification...\n",
            "WARNING:root:Perform single sequence classification...\n",
            "config.json: 100% 904/904 [00:00<00:00, 4.81MB/s]\n",
            "configuration_bert.py: 100% 1.01k/1.01k [00:00<00:00, 5.15MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- configuration_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "bert_layers.py: 100% 40.7k/40.7k [00:00<00:00, 25.9MB/s]\n",
            "flash_attn_triton.py: 100% 42.7k/42.7k [00:00<00:00, 110MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- flash_attn_triton.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "bert_padding.py: 100% 6.10k/6.10k [00:00<00:00, 23.6MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- bert_padding.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- bert_layers.py\n",
            "- flash_attn_triton.py\n",
            "- bert_padding.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "pytorch_model.bin: 100% 468M/468M [00:03<00:00, 130MB/s] \n",
            "/root/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/d064dece8a8b41d9fb8729fbe3435278786931f1/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at zhihan1996/DNABERT-2-117M were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 2,968\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3,720\n",
            "  Number of trainable parameters = 117,070,082\n",
            "{'loss': 0.6297, 'learning_rate': 2.9591280653950955e-05, 'epoch': 0.54}\n",
            "{'loss': 0.5494, 'learning_rate': 2.8773841961852862e-05, 'epoch': 1.08}\n",
            "  5% 200/3720 [37:05<10:41:44, 10.94s/it]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:02<00:29,  1.30s/it]\u001b[A\n",
            " 12% 3/25 [00:06<00:54,  2.49s/it]\u001b[A\n",
            " 16% 4/25 [00:09<00:54,  2.59s/it]\u001b[A\n",
            " 20% 5/25 [00:12<00:51,  2.55s/it]\u001b[A\n",
            " 24% 6/25 [00:14<00:48,  2.55s/it]\u001b[A\n",
            " 28% 7/25 [00:16<00:45,  2.52s/it]\u001b[A\n",
            " 32% 8/25 [00:20<00:48,  2.85s/it]\u001b[A\n",
            " 36% 9/25 [00:23<00:48,  3.02s/it]\u001b[A\n",
            " 40% 10/25 [00:26<00:42,  2.84s/it]\u001b[A\n",
            " 44% 11/25 [00:28<00:38,  2.72s/it]\u001b[A\n",
            " 48% 12/25 [00:31<00:34,  2.63s/it]\u001b[A\n",
            " 52% 13/25 [00:34<00:32,  2.70s/it]\u001b[A\n",
            " 56% 14/25 [00:37<00:33,  3.05s/it]\u001b[A\n",
            " 60% 15/25 [00:40<00:29,  2.93s/it]\u001b[A\n",
            " 64% 16/25 [00:43<00:24,  2.77s/it]\u001b[A\n",
            " 68% 17/25 [00:45<00:21,  2.67s/it]\u001b[A\n",
            " 72% 18/25 [00:47<00:18,  2.60s/it]\u001b[A\n",
            " 76% 19/25 [00:51<00:17,  2.87s/it]\u001b[A\n",
            " 80% 20/25 [00:54<00:15,  3.03s/it]\u001b[A\n",
            " 84% 21/25 [00:57<00:11,  2.86s/it]\u001b[A\n",
            " 88% 22/25 [00:59<00:08,  2.74s/it]\u001b[A\n",
            " 92% 23/25 [01:02<00:05,  2.64s/it]\u001b[A\n",
            " 96% 24/25 [01:04<00:02,  2.68s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.7193296551704407, 'eval_accuracy': 0.5225, 'eval_f1': 0.3925660902405088, 'eval_matthews_correlation': 0.11843130509275841, 'eval_precision': 0.6558441558441559, 'eval_recall': 0.5225, 'eval_runtime': 71.3783, 'eval_samples_per_second': 5.604, 'eval_steps_per_second': 0.35, 'epoch': 1.08}\n",
            "  5% 200/3720 [38:16<10:41:44, 10.94s/it]\n",
            "100% 25/25 [01:08<00:00,  3.05s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to output/dnabert2/checkpoint-200\n",
            "Configuration saved in output/dnabert2/checkpoint-200/config.json\n",
            "Model weights saved in output/dnabert2/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in output/dnabert2/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in output/dnabert2/checkpoint-200/special_tokens_map.json\n",
            "{'loss': 0.5416, 'learning_rate': 2.795640326975477e-05, 'epoch': 1.61}\n",
            "{'loss': 0.5088, 'learning_rate': 2.7138964577656677e-05, 'epoch': 2.15}\n",
            " 11% 400/3720 [1:15:12<10:24:43, 11.29s/it]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:02<00:27,  1.21s/it]\u001b[A\n",
            " 12% 3/25 [00:04<00:38,  1.75s/it]\u001b[A\n",
            " 16% 4/25 [00:08<00:52,  2.52s/it]\u001b[A\n",
            " 20% 5/25 [00:12<00:55,  2.79s/it]\u001b[A\n",
            " 24% 6/25 [00:14<00:51,  2.70s/it]\u001b[A\n",
            " 28% 7/25 [00:16<00:47,  2.62s/it]\u001b[A\n",
            " 32% 8/25 [00:19<00:43,  2.56s/it]\u001b[A\n",
            " 36% 9/25 [00:22<00:44,  2.76s/it]\u001b[A\n",
            " 40% 10/25 [00:26<00:46,  3.08s/it]\u001b[A\n",
            " 44% 11/25 [00:28<00:40,  2.90s/it]\u001b[A\n",
            " 48% 12/25 [00:31<00:35,  2.76s/it]\u001b[A\n",
            " 52% 13/25 [00:33<00:31,  2.65s/it]\u001b[A\n",
            " 56% 14/25 [00:36<00:28,  2.57s/it]\u001b[A\n",
            " 60% 15/25 [00:40<00:29,  2.97s/it]\u001b[A\n",
            " 64% 16/25 [00:43<00:26,  2.99s/it]\u001b[A\n",
            " 68% 17/25 [00:45<00:22,  2.82s/it]\u001b[A\n",
            " 72% 18/25 [00:47<00:18,  2.69s/it]\u001b[A\n",
            " 76% 19/25 [00:50<00:15,  2.61s/it]\u001b[A\n",
            " 80% 20/25 [00:53<00:13,  2.74s/it]\u001b[A\n",
            " 84% 21/25 [00:57<00:12,  3.10s/it]\u001b[A\n",
            " 88% 22/25 [00:59<00:08,  2.90s/it]\u001b[A\n",
            " 92% 23/25 [01:02<00:05,  2.76s/it]\u001b[A\n",
            " 96% 24/25 [01:04<00:02,  2.66s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.5351806879043579, 'eval_accuracy': 0.735, 'eval_f1': 0.7293087157486147, 'eval_matthews_correlation': 0.49110440368668035, 'eval_precision': 0.7565782290643084, 'eval_recall': 0.735, 'eval_runtime': 69.6075, 'eval_samples_per_second': 5.747, 'eval_steps_per_second': 0.359, 'epoch': 2.15}\n",
            " 11% 400/3720 [1:16:21<10:24:43, 11.29s/it]\n",
            "100% 25/25 [01:07<00:00,  2.58s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to output/dnabert2/checkpoint-400\n",
            "Configuration saved in output/dnabert2/checkpoint-400/config.json\n",
            "Model weights saved in output/dnabert2/checkpoint-400/pytorch_model.bin\n",
            "tokenizer config file saved in output/dnabert2/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in output/dnabert2/checkpoint-400/special_tokens_map.json\n",
            "{'loss': 0.4907, 'learning_rate': 2.6321525885558584e-05, 'epoch': 2.69}\n",
            "{'loss': 0.4708, 'learning_rate': 2.5504087193460492e-05, 'epoch': 3.23}\n",
            " 16% 600/3720 [1:53:30<9:21:20, 10.80s/it]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:02<00:31,  1.35s/it]\u001b[A\n",
            " 12% 3/25 [00:05<00:40,  1.84s/it]\u001b[A\n",
            " 16% 4/25 [00:07<00:43,  2.07s/it]\u001b[A\n",
            " 20% 5/25 [00:10<00:44,  2.23s/it]\u001b[A\n",
            " 24% 6/25 [00:13<00:51,  2.74s/it]\u001b[A\n",
            " 28% 7/25 [00:17<00:52,  2.92s/it]\u001b[A\n",
            " 32% 8/25 [00:19<00:46,  2.76s/it]\u001b[A\n",
            " 36% 9/25 [00:22<00:42,  2.67s/it]\u001b[A\n",
            " 40% 10/25 [00:24<00:39,  2.60s/it]\u001b[A\n",
            " 44% 11/25 [00:27<00:37,  2.71s/it]\u001b[A\n",
            " 48% 12/25 [00:31<00:40,  3.09s/it]\u001b[A\n",
            " 52% 13/25 [00:34<00:34,  2.92s/it]\u001b[A\n",
            " 56% 14/25 [00:36<00:30,  2.75s/it]\u001b[A\n",
            " 60% 15/25 [00:38<00:26,  2.65s/it]\u001b[A\n",
            " 64% 16/25 [00:41<00:23,  2.59s/it]\u001b[A\n",
            " 68% 17/25 [00:44<00:23,  2.91s/it]\u001b[A\n",
            " 72% 18/25 [00:48<00:21,  3.02s/it]\u001b[A\n",
            " 76% 19/25 [00:50<00:17,  2.84s/it]\u001b[A\n",
            " 80% 20/25 [00:53<00:13,  2.71s/it]\u001b[A\n",
            " 84% 21/25 [00:55<00:10,  2.64s/it]\u001b[A\n",
            " 88% 22/25 [00:58<00:08,  2.74s/it]\u001b[A\n",
            " 92% 23/25 [01:02<00:06,  3.10s/it]\u001b[A\n",
            " 96% 24/25 [01:05<00:02,  2.95s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.5958588719367981, 'eval_accuracy': 0.7625, 'eval_f1': 0.7624866398734929, 'eval_matthews_correlation': 0.525059072468666, 'eval_precision': 0.7625590757920532, 'eval_recall': 0.7625, 'eval_runtime': 71.6002, 'eval_samples_per_second': 5.587, 'eval_steps_per_second': 0.349, 'epoch': 3.23}\n",
            " 16% 600/3720 [1:54:41<9:21:20, 10.80s/it]\n",
            "100% 25/25 [01:07<00:00,  2.80s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to output/dnabert2/checkpoint-600\n",
            "Configuration saved in output/dnabert2/checkpoint-600/config.json\n",
            "Model weights saved in output/dnabert2/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in output/dnabert2/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in output/dnabert2/checkpoint-600/special_tokens_map.json\n",
            "{'loss': 0.4423, 'learning_rate': 2.46866485013624e-05, 'epoch': 3.76}\n",
            "{'loss': 0.4112, 'learning_rate': 2.3869209809264304e-05, 'epoch': 4.3}\n",
            " 22% 800/3720 [2:32:09<8:48:49, 10.87s/it]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:02<00:32,  1.42s/it]\u001b[A\n",
            " 12% 3/25 [00:05<00:41,  1.87s/it]\u001b[A\n",
            " 16% 4/25 [00:07<00:43,  2.09s/it]\u001b[A\n",
            " 20% 5/25 [00:10<00:45,  2.25s/it]\u001b[A\n",
            " 24% 6/25 [00:14<00:51,  2.73s/it]\u001b[A\n",
            " 28% 7/25 [00:17<00:52,  2.91s/it]\u001b[A\n",
            " 32% 8/25 [00:19<00:46,  2.76s/it]\u001b[A\n",
            " 36% 9/25 [00:22<00:43,  2.70s/it]\u001b[A\n",
            " 40% 10/25 [00:24<00:39,  2.62s/it]\u001b[A\n",
            " 44% 11/25 [00:27<00:38,  2.78s/it]\u001b[A\n",
            " 48% 12/25 [00:31<00:40,  3.14s/it]\u001b[A\n",
            " 52% 13/25 [00:34<00:35,  2.96s/it]\u001b[A\n",
            " 56% 14/25 [00:36<00:30,  2.78s/it]\u001b[A\n",
            " 60% 15/25 [00:39<00:26,  2.68s/it]\u001b[A\n",
            " 64% 16/25 [00:41<00:23,  2.61s/it]\u001b[A\n",
            " 68% 17/25 [00:45<00:23,  2.99s/it]\u001b[A\n",
            " 72% 18/25 [00:48<00:21,  3.05s/it]\u001b[A\n",
            " 76% 19/25 [00:51<00:17,  2.87s/it]\u001b[A\n",
            " 80% 20/25 [00:53<00:13,  2.75s/it]\u001b[A\n",
            " 84% 21/25 [00:56<00:10,  2.67s/it]\u001b[A\n",
            " 88% 22/25 [00:59<00:08,  2.81s/it]\u001b[A\n",
            " 92% 23/25 [01:03<00:06,  3.17s/it]\u001b[A\n",
            " 96% 24/25 [01:05<00:02,  2.98s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.6070153117179871, 'eval_accuracy': 0.78, 'eval_f1': 0.7799504888599935, 'eval_matthews_correlation': 0.5602521702276756, 'eval_precision': 0.7802522270043039, 'eval_recall': 0.78, 'eval_runtime': 72.3921, 'eval_samples_per_second': 5.525, 'eval_steps_per_second': 0.345, 'epoch': 4.3}\n",
            " 22% 800/3720 [2:33:21<8:48:49, 10.87s/it]\n",
            "100% 25/25 [01:08<00:00,  2.81s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to output/dnabert2/checkpoint-800\n",
            "Configuration saved in output/dnabert2/checkpoint-800/config.json\n",
            "Model weights saved in output/dnabert2/checkpoint-800/pytorch_model.bin\n",
            "tokenizer config file saved in output/dnabert2/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in output/dnabert2/checkpoint-800/special_tokens_map.json\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/DNABERT_2/finetune/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m306 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m308 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m309 \u001b[2m│   \u001b[0m\u001b[1;4mtrain()\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m310 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/DNABERT_2/finetune/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m291\u001b[0m in \u001b[92mtrain\u001b[0m                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │      \u001b[0mtrain_dataset=train_dataset,                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │      \u001b[0meval_dataset=val_dataset,                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │      \u001b[0mdata_collator=data_collator)                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   \u001b[0m\u001b[1;4mtrainer.train()\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m training_args.save_model:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer.save_state()                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2019\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2016 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.epoch = epoch + (step + \u001b[94m1\u001b[0m + steps_skipped) / steps_in_epo  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2017 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_end(args, \u001b[96mself\u001b[0m.state, \u001b[96ms\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2018 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2019 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2020 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2021 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_substep_end(args, \u001b[96mself\u001b[0m.state  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2022 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2308\u001b[0m in \u001b[92m_maybe_log_save_evaluate\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2305 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.lr_scheduler.step(metrics[\u001b[96mself\u001b[0m.args.metric_for_best_model])          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2306 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2307 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.control.should_save:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2308 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._save_checkpoint(model, trial, metrics=metrics)\u001b[0m                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2309 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_save(\u001b[96mself\u001b[0m.args, \u001b[96mself\u001b[0m.state, \u001b[96mself\u001b[0m.con  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2310 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2311 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_load_rng_state\u001b[0m(\u001b[96mself\u001b[0m, checkpoint):                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2466\u001b[0m in \u001b[92m_save_checkpoint\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2463 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2464 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Maybe delete some older checkpoints.\u001b[0m                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2465 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.should_save:                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2466 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._rotate_checkpoints(use_mtime=\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m, output_dir=run_dir)\u001b[0m                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2467 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2468 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_load_optimizer_and_scheduler\u001b[0m(\u001b[96mself\u001b[0m, checkpoint):                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2469 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"If optimizer and scheduler states exist, load them.\"\"\"\u001b[0m                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2972\u001b[0m in \u001b[92m_rotate_checkpoints\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2969 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2970 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2971 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Check if we should delete older checkpoint(s)\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2972 \u001b[2m│   │   \u001b[0mcheckpoints_sorted = \u001b[1;4;96mself\u001b[0m\u001b[1;4m._sorted_checkpoints(use_mtime=use_mtime, output_dir=ou\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2973 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(checkpoints_sorted) <= \u001b[96mself\u001b[0m.args.save_total_limit:                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2974 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2975 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2962\u001b[0m in \u001b[92m_sorted_checkpoints\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2959 \u001b[0m\u001b[2m│   │   \u001b[0mcheckpoints_sorted = [checkpoint[\u001b[94m1\u001b[0m] \u001b[94mfor\u001b[0m checkpoint \u001b[95min\u001b[0m checkpoints_sorted]         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2960 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Make sure we don't delete the best model.\u001b[0m                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2961 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.state.best_model_checkpoint \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2962 \u001b[2m│   │   │   \u001b[0mbest_model_index = \u001b[1;4mcheckpoints_sorted.index(\u001b[0m\u001b[1;4;96mstr\u001b[0m\u001b[1;4m(Path(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.state.best_model_c\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2963 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(best_model_index, \u001b[96mlen\u001b[0m(checkpoints_sorted) - \u001b[94m2\u001b[0m):                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2964 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcheckpoints_sorted[i], checkpoints_sorted[i + \u001b[94m1\u001b[0m] = checkpoints_sorted[i   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2965 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m checkpoints_sorted                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mValueError: \u001b[0m\u001b[32m'output/dnabert2/checkpoint-400'\u001b[0m is not in list\n",
            " 22% 800/3720 [2:33:41<9:20:57, 11.53s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ['DATA_PATH'] = '/content'  # Path to your data folder\n",
        "os.environ['MAX_LENGTH'] = '50'  # Set max length, adjust as needed\n",
        "os.environ['LR'] = '3e-5'  # Learning rate\n",
        "\n",
        "# Training using DataParallel\n",
        "!python /content/DNABERT_2/finetune/train.py \\\n",
        "    --model_name_or_path zhihan1996/DNABERT-2-117M \\\n",
        "    --data_path $DATA_PATH \\\n",
        "    --kmer -1 \\\n",
        "    --run_name DNABERT2_$DATA_PATH \\\n",
        "    --model_max_length $MAX_LENGTH \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --learning_rate $LR \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --save_steps 10 \\\n",
        "    --output_dir output/dnabert2 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --eval_steps 200 \\\n",
        "    --warmup_steps 50 \\\n",
        "    --logging_steps 100 \\\n",
        "    --overwrite_output_dir True \\\n",
        "    --log_level info \\\n",
        "    --find_unused_parameters False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'path_to_zip_file' with the path to your zip file\n",
        "zip_file_path = '/content/drive/MyDrive/checkpointDNABERT.zip'\n",
        "\n",
        "# Replace 'destination_folder' with the path where you want to unzip the files\n",
        "destination_folder = '/content/destination_folder'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder)\n",
        "\n",
        "print('Files extracted successfully!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnDmUYng1l-J",
        "outputId": "c44e7e2e-cfca-4913-f549-a890d314fcbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -R /content/destination_folder/checkpointDNABERT/checkpoint600"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5W2gTTRHe0Q",
        "outputId": "b5510d54-088d-41ec-a144-786c6bedbb8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/destination_folder/checkpointDNABERT/checkpoint600': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCOwDeFhTGf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/destination_folder/checkpointDNABERT/checkpoint600')\n"
      ],
      "metadata": {
        "id": "4dP6YhbHHwIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint_path = \"/content/destination_folder/checkpointDNABERT/checkpoint600\"\n",
        "\n",
        "# Load the tokenizer (ensure the tokenizer is properly configured for your DNA data)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)\n",
        "\n",
        "# Load the configuration from config.json (ensure you load the correct config)\n",
        "config = AutoConfig.from_pretrained(checkpoint_path, trust_remote_code=True)\n",
        "\n",
        "# Load the model using the custom configuration\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path, config=config, trust_remote_code=True)\n",
        "\n",
        "# Example DNA sequence input\n",
        "sequence = \"ATGCGTACGTTAGC\"\n",
        "\n",
        "# Tokenize the input sequence (ensure truncation and padding are properly handled)\n",
        "inputs = tokenizer(sequence, return_tensors=\"pt\", padding=True, truncation=True, max_length=config.max_position_embeddings)\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Forward pass: get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Output the logits (model predictions)\n",
        "logits = outputs.logits\n",
        "print(logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "I4fGCe65C6Z1",
        "outputId": "269ef4b5-be3a-48c2-ee62-9bb2a4bac97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers.models.bert.configuration_bert.BertConfig'> and you passed <class 'transformers_modules.zhihan1996.DNABERT-2-117M.d064dece8a8b41d9fb8729fbe3435278786931f1.configuration_bert.BertConfig'>. Fix one of those so they match!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a9164eec75f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the model using the custom configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Example DNA sequence input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(cls, config_class, model_class, exist_ok)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_config_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers.models.bert.configuration_bert.BertConfig'> and you passed <class 'transformers_modules.zhihan1996.DNABERT-2-117M.d064dece8a8b41d9fb8729fbe3435278786931f1.configuration_bert.BertConfig'>. Fix one of those so they match!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.configuration_bert import BertConfig\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "config = BertConfig.from_pretrained(\"/content/drive/MyDrive/checkpointDNABERT/checkpoint800\")\n",
        "model = AutoModel.from_pretrained(\"/content/drive/MyDrive/checkpointDNABERT/checkpoint800\", trust_remote_code=True, config=config)"
      ],
      "metadata": {
        "id": "zsKp_5VWDYyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785,
          "referenced_widgets": [
            "9cd9adb371324e99b817236363b277c7",
            "c6a6e00d8bd34c0eb675c461573cdbd3",
            "b43f625a153440c399c8187e40da93cb",
            "388fa4688c504896aefc2191dac6fe42",
            "b0e67b52db43413bbd24bebb2f5f76c4",
            "fd5fd0ee126341b6815bacae02b6ae1c",
            "6a22df2235d94d259e866b18836cec27",
            "3d045a8acbad45dbb5f30a391f793acc",
            "e8e09c890893416bbfb8298d5bf0a01d",
            "843d8d9fc4614842a50fc363072e8b10",
            "0de4cf8fcf434b558cc3b9a1401aa7ee",
            "13758115ed614e5fa882f9b3695d1998",
            "b4bbeb5bcca04a13a0280dcc2ca2e938",
            "8e9b3b5694a448feb01faaba90c657ce",
            "9fb511ecdec04a589731db2de7f7c0a9",
            "18368c67dc3f4c29ad34af8f2bceb62a",
            "3c0cb7a0b4104d1e9c4a6eed9e6d21ba",
            "9a98c0322f9341e48f84011fdb3fb52d",
            "0a190c64be99454fbc51e09d9eb6d4ee",
            "e5d4d15a276e483bbe9540174e5a7274",
            "18d5d4df78e54d969795b0182d19e972",
            "eb2d3d5883884db6bd06fe48d00e6872",
            "9640bef193044b74a497f9d0ee85f9a4",
            "7fbac9fcdb1e46bab3a7cb0c0084e078",
            "30bbe5a8bcb146e68213dbc5cfdc4567",
            "774584d7484848ea9a431bbec55b2df9",
            "659506751d094d4fb00f56af877278ef",
            "bed63bd2646c4bf69d8ce8b46b494142",
            "11d57c3e78734fd7acabcda4cb363688",
            "1942aef24be44e059c94050845a7060e",
            "ee541f82df894f09a54ef6347b010a30",
            "7363c872f08a4722b039cd9e9ec2d8bd",
            "2c48ec75888d43ad80699c56b87f253f"
          ]
        },
        "outputId": "e195097c-0e97-4c2a-c564-b156aef98b56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "bert_layers.py:   0%|          | 0.00/40.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cd9adb371324e99b817236363b277c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "bert_padding.py:   0%|          | 0.00/6.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13758115ed614e5fa882f9b3695d1998"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- bert_padding.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "flash_attn_triton.py:   0%|          | 0.00/42.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9640bef193044b74a497f9d0ee85f9a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- flash_attn_triton.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/zhihan1996/DNABERT-2-117M:\n",
            "- bert_layers.py\n",
            "- bert_padding.py\n",
            "- flash_attn_triton.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /content/drive/MyDrive/checkpointDNABERT/checkpoint800.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e93ac2e97146>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/checkpointDNABERT/checkpoint800\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/checkpointDNABERT/checkpoint800\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_generation_mixin_to_remote_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3777\u001b[0m                     )\n\u001b[1;32m   3778\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3779\u001b[0;31m                     raise EnvironmentError(\n\u001b[0m\u001b[1;32m   3780\u001b[0m                         \u001b[0;34mf\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3781\u001b[0m                         \u001b[0;34mf\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /content/drive/MyDrive/checkpointDNABERT/checkpoint800."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHZPFmb0VB5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cd9adb371324e99b817236363b277c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6a6e00d8bd34c0eb675c461573cdbd3",
              "IPY_MODEL_b43f625a153440c399c8187e40da93cb",
              "IPY_MODEL_388fa4688c504896aefc2191dac6fe42"
            ],
            "layout": "IPY_MODEL_b0e67b52db43413bbd24bebb2f5f76c4"
          }
        },
        "c6a6e00d8bd34c0eb675c461573cdbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5fd0ee126341b6815bacae02b6ae1c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a22df2235d94d259e866b18836cec27",
            "value": "bert_layers.py: 100%"
          }
        },
        "b43f625a153440c399c8187e40da93cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d045a8acbad45dbb5f30a391f793acc",
            "max": 40690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8e09c890893416bbfb8298d5bf0a01d",
            "value": 40690
          }
        },
        "388fa4688c504896aefc2191dac6fe42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843d8d9fc4614842a50fc363072e8b10",
            "placeholder": "​",
            "style": "IPY_MODEL_0de4cf8fcf434b558cc3b9a1401aa7ee",
            "value": " 40.7k/40.7k [00:00&lt;00:00, 1.30MB/s]"
          }
        },
        "b0e67b52db43413bbd24bebb2f5f76c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5fd0ee126341b6815bacae02b6ae1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a22df2235d94d259e866b18836cec27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d045a8acbad45dbb5f30a391f793acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e09c890893416bbfb8298d5bf0a01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "843d8d9fc4614842a50fc363072e8b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de4cf8fcf434b558cc3b9a1401aa7ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13758115ed614e5fa882f9b3695d1998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4bbeb5bcca04a13a0280dcc2ca2e938",
              "IPY_MODEL_8e9b3b5694a448feb01faaba90c657ce",
              "IPY_MODEL_9fb511ecdec04a589731db2de7f7c0a9"
            ],
            "layout": "IPY_MODEL_18368c67dc3f4c29ad34af8f2bceb62a"
          }
        },
        "b4bbeb5bcca04a13a0280dcc2ca2e938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0cb7a0b4104d1e9c4a6eed9e6d21ba",
            "placeholder": "​",
            "style": "IPY_MODEL_9a98c0322f9341e48f84011fdb3fb52d",
            "value": "bert_padding.py: 100%"
          }
        },
        "8e9b3b5694a448feb01faaba90c657ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a190c64be99454fbc51e09d9eb6d4ee",
            "max": 6099,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5d4d15a276e483bbe9540174e5a7274",
            "value": 6099
          }
        },
        "9fb511ecdec04a589731db2de7f7c0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d5d4df78e54d969795b0182d19e972",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2d3d5883884db6bd06fe48d00e6872",
            "value": " 6.10k/6.10k [00:00&lt;00:00, 397kB/s]"
          }
        },
        "18368c67dc3f4c29ad34af8f2bceb62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0cb7a0b4104d1e9c4a6eed9e6d21ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a98c0322f9341e48f84011fdb3fb52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a190c64be99454fbc51e09d9eb6d4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d4d15a276e483bbe9540174e5a7274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18d5d4df78e54d969795b0182d19e972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2d3d5883884db6bd06fe48d00e6872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9640bef193044b74a497f9d0ee85f9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fbac9fcdb1e46bab3a7cb0c0084e078",
              "IPY_MODEL_30bbe5a8bcb146e68213dbc5cfdc4567",
              "IPY_MODEL_774584d7484848ea9a431bbec55b2df9"
            ],
            "layout": "IPY_MODEL_659506751d094d4fb00f56af877278ef"
          }
        },
        "7fbac9fcdb1e46bab3a7cb0c0084e078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed63bd2646c4bf69d8ce8b46b494142",
            "placeholder": "​",
            "style": "IPY_MODEL_11d57c3e78734fd7acabcda4cb363688",
            "value": "flash_attn_triton.py: 100%"
          }
        },
        "30bbe5a8bcb146e68213dbc5cfdc4567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1942aef24be44e059c94050845a7060e",
            "max": 42737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee541f82df894f09a54ef6347b010a30",
            "value": 42737
          }
        },
        "774584d7484848ea9a431bbec55b2df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7363c872f08a4722b039cd9e9ec2d8bd",
            "placeholder": "​",
            "style": "IPY_MODEL_2c48ec75888d43ad80699c56b87f253f",
            "value": " 42.7k/42.7k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "659506751d094d4fb00f56af877278ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed63bd2646c4bf69d8ce8b46b494142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d57c3e78734fd7acabcda4cb363688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1942aef24be44e059c94050845a7060e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee541f82df894f09a54ef6347b010a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7363c872f08a4722b039cd9e9ec2d8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c48ec75888d43ad80699c56b87f253f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}